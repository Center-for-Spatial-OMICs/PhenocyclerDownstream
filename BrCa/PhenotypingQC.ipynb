{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/plummergrp/QuPath_0.4.4/BrCa\n"
     ]
    }
   ],
   "source": [
    "# import the needed packages\n",
    "import pandas as pd\n",
    "import stlearn as st\n",
    "import scanpy as sc\n",
    "import scanpy.external as sce\n",
    "# import squidpy as sq\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import anndata as ad\n",
    "from anndata import AnnData\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns; sns.set(color_codes=True)\n",
    "import monkeybread as mb\n",
    "\n",
    "import cupy as cp\n",
    "import time\n",
    "import rapids_singlecell as rsc\n",
    "\n",
    "import scimap as sm\n",
    "\n",
    "# make sure that we are in the right directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# set the filenames we are looking at\n",
    "filenames = [\"S17_7722_E4\",\"S1614455_C21\",\"S17_16197_A1\",\"S18_13562_A1\",\"S18_5464_A1\",\"S18_13562_B1\",\"S17_10147B7_S2\"]\n",
    "pop_samples = ['Haitian','Haitian','African American','African American','Haitian','African American','Haitian']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map the phenotypes onto the tissues\n",
    "adata = ad.read_h5ad('./session_file.h5ad')\n",
    "newAD = ad.read_h5ad('./session_file_scimap_v8_scaled.h5ad')\n",
    "\n",
    "adata.obs['phenotype'] = newAD.obs['phenotype'].astype('category')\n",
    "adata.obs['phenotype'] = adata.obs['phenotype'].str.replace('likely-', '').astype('category')\n",
    "\n",
    "# remove the \"other cells\"\n",
    "adata = adata[(adata.obs['phenotype'] != 'Non-Immune cells') & (adata.obs['phenotype'] != 'Other Immune cells')]\n",
    "\n",
    "adatas_sm = []\n",
    "\n",
    "for i in range(len(filenames)):\n",
    "    adatas_sm.append(adata[adata.obs['ImageID'] == filenames[i]])\n",
    "    # print(adatas_sm[i])\n",
    "    st.pl.cluster_plot(adatas_sm[i],use_label=\"phenotype\", show_cluster_labels=False, size=0.5, figsize=(8, 8), cmap='tab20')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate random squares of the images \n",
    "import random\n",
    "radius_box = 400 # radius box sizes\n",
    "num_sq = 50 # how many random squares we generate for each sample\n",
    "min_cells = 100 # lowest number of cells allowed\n",
    "\n",
    "# load in the workflow\n",
    "phenoDF = pd.read_csv('../SciMap/phenotype_workflow.csv')\n",
    "\n",
    "# define a function that flattens list which is useful later on\n",
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "# initialize the lists/dfs used to store the scores and the mistakes\n",
    "df_mistakes = pd.DataFrame(0, index=adatas_sm[0].obs['phenotype'].unique().tolist(), columns=['num_mistakes', 'num_total', '%_wrong'])\n",
    "df_gene_mistakes = pd.DataFrame(0, index=adatas_sm[0].obs['phenotype'].unique().tolist(), columns=pd.Index.tolist(adatas_sm[0].var_names))\n",
    "\n",
    "total_cells = 0\n",
    "for i in range(len(filenames)):\n",
    "    # scale the data\n",
    "    temp_uncut = adatas_sm[i].copy()\n",
    "    st.pp.scale(temp_uncut, zero_center=True)\n",
    "\n",
    "    # calculate the standard deviations we are going to use\n",
    "    groups_tot = temp_uncut.obs['phenotype'].unique().tolist()\n",
    "    genes_tot = pd.Index.tolist(temp_uncut.var_names)\n",
    "    df_tot = pd.DataFrame(columns=genes_tot, index=groups_tot)\n",
    "    temp_pheno = temp_uncut.obs['phenotype']\n",
    "    X_temp_uncut = np.array(temp_uncut.X)\n",
    "\n",
    "\n",
    "    # for each element in the table, calculate the mean expression\n",
    "    for group in groups_tot:\n",
    "        phenotype_cells = X_temp_uncut[temp_pheno == group, :]\n",
    "        mean_expression = phenotype_cells.mean(axis=0)\n",
    "        df_tot.loc[group] = mean_expression\n",
    "    mystd = df_tot.std()\n",
    "    \n",
    "    j = 0\n",
    "    while j < num_sq:\n",
    "        # draw a box for where the centroids can be such that it wont touch the edge\n",
    "        x_min = min(temp_uncut.obs[\"imagecol\"])+radius_box\n",
    "        x_max = max(temp_uncut.obs[\"imagecol\"])-radius_box\n",
    "        y_min = min(temp_uncut.obs[\"imagerow\"])+radius_box\n",
    "        y_max = max(temp_uncut.obs[\"imagerow\"])-radius_box\n",
    "\n",
    "        # randomly generate a centroid\n",
    "        x_cent = random.random()*(x_max-x_min)+x_min\n",
    "        y_cent = random.random()*(y_max-y_min)+y_min\n",
    "        # print(str(x_cent) + \", \" + str(y_cent))\n",
    "\n",
    "        x_min_cut = x_cent-radius_box # want x to be bigger than this value\n",
    "        x_max_cut = x_cent+radius_box # want x to be smaller than this value\n",
    "        y_min_cut = y_cent-radius_box # want y to be bigger than this value\n",
    "        y_max_cut = y_cent+radius_box # want y to be smaller than this value\n",
    "\n",
    "        # create the randomly drawn box\n",
    "        temp_scaled = temp_uncut[(temp_uncut.obs['imagecol']>x_min_cut) \n",
    "                            & (temp_uncut.obs['imagecol']<x_max_cut)\n",
    "                            & (temp_uncut.obs['imagerow']>y_min_cut)\n",
    "                            & (temp_uncut.obs['imagerow']<y_max_cut)]\n",
    "\n",
    "        # print(temp)\n",
    "        if(len(temp_scaled)>min_cells):\n",
    "            total_cells = total_cells + len(temp_scaled)\n",
    "            genes = pd.Index.tolist(temp_scaled.var_names)\n",
    "\n",
    "            # create cluster plot\n",
    "            # st.pl.cluster_plot(temp_scaled,use_label=\"phenotype\", show_cluster_labels=False, size=12, figsize=(8, 8), title=filenames[i])\n",
    "            \n",
    "            # create gene expression dotplot\n",
    "            # sc.pl.dotplot(temp_scaled, genes, groupby='phenotype', dendrogram=False, title=filenames[i])\n",
    "\n",
    "            # create a data frame that is cell types x genes\n",
    "            groups = temp_scaled.obs['phenotype'].unique().tolist()\n",
    "            genes = pd.Index.tolist(temp_scaled.var_names)\n",
    "            df = df_tot.loc[groups]\n",
    "\n",
    "            # create a workflow table that is correspondant with the subsample\n",
    "            absentCells = list((set(groups) ^ set(adata.obs['phenotype'].unique().tolist())))\n",
    "            temp_phenoDF = phenoDF[~phenoDF['Unnamed: 1'].isin(absentCells)].copy()\n",
    "            temp_phenoDF.drop(inplace=True, columns = 'Unnamed: 0')\n",
    "            temp_phenoDF.set_index('Unnamed: 1', inplace=True)\n",
    "            \n",
    "            # compare the workflow with the mean expression\n",
    "            # correctness:\n",
    "            # if the workflow indicates pos, and the mean expression is >1 std\n",
    "            # if the workflow indicates NaN, and the mean expression is >-1 std and <1 std\n",
    "            # if the workflow indicates neg, and the mean expression is <-1 std\n",
    "\n",
    "            for group in groups:\n",
    "                for gene in genes:\n",
    "                    df_mistakes.at[group, 'num_total'] = df_mistakes.at[group, 'num_total'] + 1\n",
    "                    if (type(temp_phenoDF.at[group, gene]) == np.float64 or type(temp_phenoDF.at[group, gene]) == float) and pd.isna(temp_phenoDF.at[group, gene]):\n",
    "                        if abs(df.at[group, gene]) > mystd[gene]:\n",
    "                            df_mistakes.at[group, 'num_mistakes'] = df_mistakes.at[group, 'num_mistakes'] + 1\n",
    "                            df_gene_mistakes.at[group, gene] = df_gene_mistakes.at[group, gene] + 1\n",
    "                    elif isinstance(temp_phenoDF.at[group, gene], str) and 'pos' in temp_phenoDF.at[group, gene]:\n",
    "                        if df.at[group, gene] <= mystd[gene]:\n",
    "                            df_mistakes.at[group, 'num_mistakes'] = df_mistakes.at[group, 'num_mistakes'] + 1\n",
    "                            df_gene_mistakes.at[group, gene] = df_gene_mistakes.at[group, gene] + 1\n",
    "                    elif isinstance(temp_phenoDF.at[group, gene], str) and 'neg' in temp_phenoDF.at[group, gene]:\n",
    "                        if df.at[group, gene] >= -mystd[gene]:\n",
    "                            df_mistakes.at[group, 'num_mistakes'] = df_mistakes.at[group, 'num_mistakes'] + 1\n",
    "                            df_gene_mistakes.at[group, gene] = df_gene_mistakes.at[group, gene] + 1\n",
    "            j = j+1\n",
    "\n",
    "# find out which cell types are most falsely identified\n",
    "for group in df_mistakes.index.tolist():\n",
    "    df_mistakes.at[group, '%_wrong'] = (df_mistakes.at[group, 'num_mistakes']*100)/df_mistakes.at[group, 'num_total']\n",
    "df_mistakes.sort_values(inplace=True, by='%_wrong', ascending=False)\n",
    "print(df_mistakes)\n",
    "\n",
    "# print total score\n",
    "print(((sum(df_mistakes['num_total'])-sum(df_mistakes['num_mistakes']))/sum(df_mistakes['num_total']))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find out the % of mistake for each gene by cell type\n",
    "df_gene_mistakes_percent = pd.DataFrame(0, index=adatas_sm[0].obs['phenotype'].unique().tolist(), columns=pd.Index.tolist(adatas_sm[0].var_names))\n",
    "for group in df_gene_mistakes.index.tolist():\n",
    "    for gene in df_gene_mistakes.columns.tolist():\n",
    "        df_gene_mistakes_percent.at[group, gene] = (df_gene_mistakes.at[group, gene]*100)/(df_mistakes.at[group, 'num_total']/len(df_gene_mistakes.columns.tolist()))\n",
    "\n",
    "df_gene_mistakes_percent.style.background_gradient(cmap ='viridis', axis=None)\\\n",
    "        .set_properties(**{'font-size': '20px'}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find out which genes have the most mistakes\n",
    "df_gene_summed_mistakes = pd.DataFrame(0, index=df_gene_mistakes.columns.tolist(), columns=['%_mistakes'])\n",
    "for gene in df_gene_mistakes.columns.tolist():\n",
    "    df_gene_summed_mistakes.at[gene, '%_mistakes'] = (sum(df_gene_mistakes[gene])/(sum(df_mistakes['num_total'])/len(df_gene_mistakes.columns.tolist())))*100\n",
    "df_gene_summed_mistakes.sort_values(inplace=True, by='%_mistakes', ascending=False)\n",
    "print(df_gene_summed_mistakes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# phenotype the cells manually to test the logic\n",
    "df_cell_genes = pd.DataFrame(0, index=list(range(0, len(temp_scaled.obs_names))), columns=temp_scaled.var_names)\n",
    "# create an expression matrix in np array so it runs exponentially faster\n",
    "exp_mat = np.array(temp_scaled.X)\n",
    "\n",
    "# turn the matrix into a ternary:\n",
    "# 1: the expression is >1 std --> upregulated\n",
    "# 0: the expression is within 1 std \n",
    "# -1: the expression is <-1 std --> downregulated\n",
    "\n",
    "for i in range(len(df_cell_genes)):\n",
    "   j = 0\n",
    "   for gene in temp_scaled.var_names:\n",
    "      if exp_mat[i, j] > mystd[gene]:\n",
    "         df_cell_genes.at[i, gene] = 1\n",
    "      elif exp_mat[i, j]< -mystd[gene]:\n",
    "         df_cell_genes.at[i, gene] = -1\n",
    "      j = j+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the workflow\n",
    "phenoDF = pd.read_csv('../SciMap/phenotype_workflow.csv')\n",
    "phenoDF.drop(inplace=True, columns = 'Unnamed: 0')\n",
    "phenoDF.set_index('Unnamed: 1', inplace=True)\n",
    "\n",
    "# generate anypos cell types + genes\n",
    "df_anypos = pd.DataFrame(columns=['phenotypes', 'genes'])\n",
    "\n",
    "# iterate over rows in 'df_pheno' and filter based on the condition\n",
    "for index, row in phenoDF.iterrows():\n",
    "    if 'anypos' in row.values:\n",
    "        cell_type = index\n",
    "        genes_with_anypos = row[row == 'anypos'].index.tolist()\n",
    "\n",
    "        # append the cell type and gene list to the new DataFrame\n",
    "        df_anypos = pd.concat([df_anypos, pd.DataFrame({'phenotypes': cell_type, 'genes': genes_with_anypos})], ignore_index=True)\n",
    "\n",
    "# reset the index using the genes for ease of access\n",
    "df_anypos.set_index('genes', inplace=True)\n",
    "# print(df_anypos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score the cell types using the difference between the standard deviation and the expression level\n",
    "exp_mat = np.array(temp_scaled.X)\n",
    "cell_phenotypes = []\n",
    "factor = 3\n",
    "\n",
    "for i in range(len(exp_mat)):\n",
    "    single_use_phenotypes = pd.DataFrame(0, index=groups_tot, columns=['score'])\n",
    "    for group in groups_tot:\n",
    "        score = 0\n",
    "        j = 0\n",
    "        for gene in genes_tot:\n",
    "            if (type(phenoDF.at[group, gene]) == np.float64 or type(phenoDF.at[group, gene]) == float) and pd.isna(phenoDF.at[group, gene]):\n",
    "                diff = abs(exp_mat[i, j]) - abs(mystd[gene])\n",
    "                if abs(exp_mat[i, j]) <= mystd[gene]:\n",
    "                    score = score + diff\n",
    "                else:\n",
    "                    score = score - diff\n",
    "            elif isinstance(phenoDF.at[group, gene], str) and 'pos' in phenoDF.at[group, gene]:\n",
    "                diff = abs(exp_mat[i, j] - mystd[gene])\n",
    "                if exp_mat[i, j] > mystd[gene]:\n",
    "                    score = score + (diff**factor)\n",
    "                else:\n",
    "                    score = score - (diff**(factor/3))\n",
    "            elif isinstance(phenoDF.at[group, gene], str) and 'neg' in phenoDF.at[group, gene]:\n",
    "                diff = abs(exp_mat[i, j]) + (mystd[gene])\n",
    "                if exp_mat[i, j] < -mystd[gene]:\n",
    "                    score = score + (diff**factor)\n",
    "                else:\n",
    "                    score = score - (diff**(factor/3))\n",
    "            j = j + 1\n",
    "        single_use_phenotypes.at[group, 'score'] = score\n",
    "    cell_phenotypes.append(str(single_use_phenotypes.sort_values(ascending=False, by='score').index[0]))\n",
    "print(cell_phenotypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.pl.cluster_plot(temp_scaled,use_label=\"phenotype\", show_cluster_labels=False, size=12, figsize=(8, 8))\n",
    "cell_phenotypes = pd.Series(cell_phenotypes)\n",
    "temp_scaled.obs['custom_pheno'] = cell_phenotypes.to_numpy()\n",
    "temp_scaled.obs['custom_pheno'] = temp_scaled.obs['custom_pheno'].astype('category')\n",
    "st.pl.cluster_plot(temp_scaled,use_label=\"custom_pheno\", show_cluster_labels=False, size=12, figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the ARI between the clusters\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "print(adjusted_rand_score(temp_scaled.obs['phenotype'], temp_scaled.obs['custom_pheno']))\n",
    "# oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_phenotypes = []\n",
    "i = 0\n",
    "# for i in range(len(df_cell_genes)):\n",
    "    # for gene in df_anypos.index.tolist():\n",
    "    #    if df_cell_genes.at[i, gene] == 1:\n",
    "    #        cell_phenotypes.append(df_anypos.at[gene, 'phenotypes'])\n",
    "single_use_phenotypes = pd.DataFrame(0, index=groups_tot, columns=['score'])\n",
    "for group in groups_tot:\n",
    "    correct = 0\n",
    "    for gene in genes_tot:\n",
    "        if (type(phenoDF.at[group, gene]) == np.float64 or type(phenoDF.at[group, gene]) == float) and pd.isna(phenoDF.at[group, gene]):\n",
    "            if df_cell_genes.at[i, gene] == 0:\n",
    "                correct = correct + 1\n",
    "            else:\n",
    "                correct = correct - 1\n",
    "        elif isinstance(phenoDF.at[group, gene], str) and 'pos' in phenoDF.at[group, gene]:\n",
    "            if df_cell_genes.at[i, gene] == 1:\n",
    "                correct = correct + 3\n",
    "            else:\n",
    "                correct = correct - 1\n",
    "        elif isinstance(phenoDF.at[group, gene], str) and 'neg' in phenoDF.at[group, gene]:\n",
    "            if df_cell_genes.at[i, gene] == -1:\n",
    "                correct = correct + 3\n",
    "            else:\n",
    "                correct = correct - 1\n",
    "    single_use_phenotypes.at[group, 'score'] = correct\n",
    "print(single_use_phenotypes.sort_values(ascending=False, by='score'))\n",
    "            \n",
    "# print(pd.DataFrame(cell_phenotypes, columns=['phenotypes']).value_counts())\n",
    "# print(temp_scaled.obs['phenotype'].value_counts())\n",
    "# print(len(temp_scaled.obs['phenotype']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stlearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
